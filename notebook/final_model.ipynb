{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FdqcMXk96rS"
   },
   "source": [
    "### Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111336,
     "status": "ok",
     "timestamp": 1671096923915,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "PxUZy3U-fjcm",
    "outputId": "ad73a1df-91ff-4e03-97d9-c5dd4137ace6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My Drive/Colab Notebooks/AN2DL/Homework2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfehjCy896Fd"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1671096961933,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "Z_wVYNVVfr6q",
    "outputId": "5c9d6c55-8186-46ef-9457-91898aa9d05b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Dense,Concatenate,Add,Average\n",
    "from keras.layers import GlobalAveragePooling1D,Bidirectional,LSTM,Conv1D,MaxPooling1D\n",
    "from keras.models import Model\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4055,
     "status": "ok",
     "timestamp": 1671097045189,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "zfGurrEjI6Y-"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "#LOG_DIR = Path() / 'kerastuner_logs' / str(int(time.time()))\n",
    "LOG_DIR = Path() / 'kerastuner_logs' / '1671115788'\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwHJ22GQrb52"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1706,
     "status": "ok",
     "timestamp": 1671097053604,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "Q_l-pqIAaZYz"
   },
   "outputs": [],
   "source": [
    "#!unzip 'training_dataset_homework2'\n",
    "X_data = np.load('x_train.npy')\n",
    "y_data = keras.utils.to_categorical(np.load('y_train.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1671097053605,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "9ct4NMHLatET",
    "outputId": "3a9ad302-10ad-454a-dcc9-9876270b8239"
   },
   "outputs": [],
   "source": [
    "print(f'{X_data.shape=}')\n",
    "print(f'{y_data.shape=}')\n",
    "print(f'We have {X_data.shape[0]} samples, each of which is a time series with {X_data.shape[1]} time steps and {X_data.shape[2]} features. We have to classify {y_data.shape[1]} classes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "MODELS_DIR = Path() / 'models'\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REPORT_DIR = Path() / 'report_material'\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INPUT_SHAPE = X_data.shape[1:]\n",
    "NUM_CLASSES = y_data.shape[-1]\n",
    "\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1671097053605,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "ySAaFOPsmGk-"
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"Wish\" : 0,\n",
    "    \"Another\" : 1,\n",
    "    \"Comfortably\" : 2,\n",
    "    \"Money\" : 3,\n",
    "    \"Breathe\" : 4,\n",
    "    \"Time\" : 5,\n",
    "    \"Brain\" : 6,\n",
    "    \"Echoes\" : 7,\n",
    "    \"Wearing\" : 8,\n",
    "    \"Sorrow\" : 9,\n",
    "    \"Hey\" : 10,\n",
    "    \"Shine\" : 11\n",
    "}\n",
    "\n",
    "LABELS = list(label_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ints = [y.argmax() for y in y_data]\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes=np.unique(y_ints),\n",
    "                                                  y=y_ints)\n",
    "\n",
    "class_weights = dict(zip(np.unique(y_ints), class_weights))\n",
    "#class_weights = dict(zip(label_mapping.keys(), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_ints, return_counts=True)\n",
    "counts\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,1.5))\n",
    "\n",
    "plt.bar(range(len(counts)), list(counts), align='center')\n",
    "plt.xticks(range(len(label_mapping)), list(label_mapping.keys()))\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, ha='right', rotation_mode='anchor')\n",
    "\n",
    "filename = f'class_imbalance.pdf'\n",
    "plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = X_data.shape[2]\n",
    "DATUM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "for i in range(NUM_FEATURES):\n",
    "    ax = plt.subplot(3, 2, i + 1)\n",
    "    ax.plot(X_data[DATUM,:,i])\n",
    "    #ax.grid()\n",
    "    ax.set_title(f'Feature {i+1}')\n",
    "    #ax.set_xlabel(\"t\")\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = f'datum_{DATUM}.pdf'\n",
    "plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "    \n",
    "ax.plot(X_data[5])\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1671097056342,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "a4_OYb31e76V",
    "outputId": "c8739775-d716-4ec8-eb28-8d3997a023a0"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.15, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671097060253,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "w4ASfcBBDDCi"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1671097061927,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "wWt_VnPI_zbD",
    "outputId": "eb128904-1c0e-4ee1-ae3f-af8f156db5e4"
   },
   "outputs": [],
   "source": [
    "print(scaler.mean_)\n",
    "print(np.sqrt(scaler.var_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1670877597818,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "6G3hLn4YYFxZ",
    "outputId": "1a41c969-b4c4-4676-f89b-083475e98516"
   },
   "outputs": [],
   "source": [
    "# save scaler\n",
    "joblib.dump(scaler, Path() / 'submission' / 'scaler.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the following parameter is set to `True` all the models will be run with data augmentation, except the Keras tuner one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this [GitHub repo](https://github.com/uchidalab/time_series_augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.datasets as ds\n",
    "import utils.augmentation as aug\n",
    "import utils.helper as hlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=10)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "sample_1d = X_train[DATUM,:,FEATURE] # sample 5, feature 3, from the normalized dataset\n",
    "sample_3d = np.expand_dims(sample_1d, axis=0)\n",
    "sample_3d = np.expand_dims(sample_3d, axis=2)\n",
    "\n",
    "fig, ax = plt.subplots(3, 2)\n",
    "\n",
    "ax[0,0].plot(sample_1d)\n",
    "ax[0,0].set_title(f'Original')\n",
    "\n",
    "temp = aug.jitter(sample_3d)[0,:,0]\n",
    "ax[0,1].plot(sample_1d)\n",
    "ax[0,1].plot(temp, linewidth = 1)\n",
    "ax[0,1].set_title(f'Jitter')\n",
    "\n",
    "temp = aug.scaling(sample_3d)[0,:,0]\n",
    "ax[1,0].plot(sample_1d)\n",
    "ax[1,0].plot(temp, linewidth = 1)\n",
    "ax[1,0].set_title(f'Scaling')\n",
    "\n",
    "temp = aug.permutation(sample_3d)[0,:,0]\n",
    "ax[1,1].plot(sample_1d)\n",
    "ax[1,1].plot(temp, linewidth = 1)\n",
    "ax[1,1].set_title(f'Permutation')\n",
    "\n",
    "temp = aug.window_slice(sample_3d)[0,:,0]\n",
    "ax[2,0].plot(sample_1d)\n",
    "ax[2,0].plot(temp, linewidth = 1)\n",
    "ax[2,0].set_title(f'Window Slicing')\n",
    "\n",
    "temp = aug.time_warp(sample_3d)[0,:,0]\n",
    "ax[2,1].plot(sample_1d)\n",
    "ax[2,1].plot(temp, linewidth = 1)\n",
    "ax[2,1].set_title(f'Time Warp')\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = 'augmentation_vis.pdf'\n",
    "plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Augmentation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_augmentation(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            inputs = inputs.numpy()\n",
    "            inputs = aug.scaling(inputs)\n",
    "            inputs = aug.permutation(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFxpvl28qTlA"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_data, eval_y_true, normalized=True, sig_fig=4, save=False, filename='confusion'):\n",
    "    \n",
    "    # get the predictions\n",
    "    eval_y_pred = np.argmax(model.predict(eval_data, verbose=0), axis=-1)\n",
    "    eval_y_true = np.argmax(eval_y_true, axis=-1)\n",
    "    \n",
    "    # compute the confusion matrix\n",
    "    cm = confusion_matrix(eval_y_true, eval_y_pred)\n",
    "    \n",
    "    # normalize if needed\n",
    "    if normalized:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # compute classification metrics\n",
    "    accuracy = accuracy_score(eval_y_true, eval_y_pred)\n",
    "    f1 = f1_score(eval_y_true, eval_y_pred, average=None)\n",
    "    print('Accuracy:', np.round(accuracy, sig_fig))\n",
    "    print('F1-scores:')\n",
    "    for i,label in enumerate(LABELS):\n",
    "        print(f'{label:<14} {np.round(f1[i], sig_fig)}')\n",
    "    \n",
    "    plt.rc('font', size=6)\n",
    "\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    sns.heatmap(cm, cmap='Blues', annot=True)  # annot=True to annotate cells, fmt='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    #ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(LABELS)\n",
    "    ax.yaxis.set_ticklabels(LABELS)\n",
    "    \n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "    plt.setp(ax.get_yticklabels(), rotation=0, ha='right', rotation_mode='anchor')\n",
    "    \n",
    "    if save:\n",
    "        filename = filename + '.pdf'\n",
    "        plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_history(history, save=False, filename='history', show_lr=True):\n",
    "    \"\"\"Prints the diagnostic plot\"\"\"\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    #plt.style.use('ggplot')\n",
    "    plt.rc('font', size=8)\n",
    "    \n",
    "    if show_lr:\n",
    "        fig, (ax1,ax2,ax3) = plt.subplots(3, sharex=True)\n",
    "    else:\n",
    "        fig, (ax1,ax2) = plt.subplots(2, sharex=True)\n",
    "    \n",
    "    #fig.suptitle('Training and validation')\n",
    "    \n",
    "    best_epoch = np.argmin(history.history['val_loss'])\n",
    "\n",
    "    ax1.plot(history.history['accuracy'], label='Training accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "    ax1.axvline(x=best_epoch, label='Best Epoch (lowest loss)', alpha=.3, ls='--', color='#5a9aa5')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    #ax1.set_xlabel('Epochs')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax1.grid(alpha=.3)\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation loss')\n",
    "    ax2.axvline(x=best_epoch, label='Best Epoch (lowest loss)', alpha=.3, ls='--', color='#5a9aa5')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    #ax2.set_xlabel('Epochs')\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.grid(alpha=.3)\n",
    "    \n",
    "    if show_lr:\n",
    "        ax3.plot(history.history['lr'], label='Learning Rate')\n",
    "        ax3.axvline(x=best_epoch, label='Best Epoch (lowest loss)', alpha=.3, ls='--', color='#5a9aa5')\n",
    "        ax3.set_ylabel('Learning Rate')\n",
    "        ax3.set_xlabel('Epochs')\n",
    "        ax3.legend(loc='upper left')\n",
    "        ax3.grid(alpha=.3)\n",
    "    \n",
    "    if save:\n",
    "        filename = filename + '.pdf'\n",
    "        plt.savefig(str(REPORT_DIR / filename), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=5, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    )\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinitialize(model):\n",
    "    for l in model.layers:\n",
    "        if hasattr(l,\"kernel_initializer\"):\n",
    "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
    "        if hasattr(l,\"bias_initializer\"):\n",
    "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
    "        if hasattr(l,\"recurrent_initializer\"):\n",
    "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAP1pRLKN_v9"
   },
   "source": [
    "### Vanilla Long Short Term Memory (LSTM) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vn115JrZjdTT"
   },
   "outputs": [],
   "source": [
    "def build_LSTM_classifier(aug=False):\n",
    "\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    x = input_layer\n",
    "    \n",
    "    if aug:\n",
    "        x = data_augmentation()(x)\n",
    "\n",
    "    # Feature extractor\n",
    "    x = LSTM(128, return_sequences=True)(x)\n",
    "    x = LSTM(128)(x)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy', run_eagerly=aug)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1670864152266,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "SE7LPD2WKMvP",
    "outputId": "629c4664-68ba-4f06-a502-c66b947785b4"
   },
   "outputs": [],
   "source": [
    "model = build_LSTM_classifier(aug=AUGMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87435,
     "status": "ok",
     "timestamp": 1670864243544,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "xujngeFRKMsu",
    "outputId": "0820e734-327e-4f34-c569-5277cdcd8c1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history, save=True, filename='history_lstm', show_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODELS_DIR / 'lstm-0.6877.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR / 'lstm-0.6877.h5', custom_objects={'data_augmentation': data_augmentation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jtq-ADVBppqm"
   },
   "source": [
    "### Bidirectional Long Short Term Memory (BiLSTM) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QRxQfedpoTe"
   },
   "outputs": [],
   "source": [
    "def build_BiLSTM_classifier(aug=False):\n",
    "\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    x = input_layer\n",
    "    \n",
    "    if aug:\n",
    "        x = data_augmentation()(x)\n",
    "\n",
    "    # Feature extractor\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    x = Bidirectional(LSTM(128))(x)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy', run_eagerly=aug)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1277,
     "status": "ok",
     "timestamp": 1670864275667,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "bmDLP1-jp9uk",
    "outputId": "4fb7cfad-991a-4c1b-b70b-e6d1fbea4917"
   },
   "outputs": [],
   "source": [
    "model = build_BiLSTM_classifier(aug=AUGMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144719,
     "status": "ok",
     "timestamp": 1670864420379,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "DZ_ehXd5sKpO",
    "outputId": "5ab0d8df-cd21-4a6e-e153-72259f5a9d9a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history, save=True, filename='history_bilstm', show_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODELS_DIR / 'bilstm-0.7479.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR / 'bilstm-0.7479.h5', custom_objects={'data_augmentation': data_augmentation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWJd-wJ-symm"
   },
   "source": [
    "### 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hU4rRA02symn"
   },
   "outputs": [],
   "source": [
    "def build_1DCNN_classifier(aug=False):\n",
    "\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    x = input_layer\n",
    "    \n",
    "    if aug:\n",
    "        x = data_augmentation()(x)\n",
    "    \n",
    "    # Feature extractor\n",
    "    filters = [2**i for i in range(6,10)]\n",
    "    for f in filters:\n",
    "        x = Conv1D(f,3,padding='same',activation='relu')(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    \n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy', run_eagerly=aug)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvUz7F3csymo"
   },
   "outputs": [],
   "source": [
    "model = build_1DCNN_classifier(aug=AUGMENTATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66795,
     "status": "ok",
     "timestamp": 1671008493087,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "1l5yKIuGsymp",
    "outputId": "8f378eac-d6a7-426f-e5c9-e66f136d9436",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "executionInfo": {
     "elapsed": 2876,
     "status": "ok",
     "timestamp": 1671008510478,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "nCHA7LjIsymp",
    "outputId": "1b6446c5-6c5c-4760-9bb0-037147ef30a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history, save=True, filename='history_1dcnn', show_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 736
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1671008550331,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "cZjthU7Tsymq",
    "outputId": "2d679f34-20bf-4285-8ec2-f59b21483cf9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODELS_DIR / '1dcnn-0.7452.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR / '1dcnn-0.7452.h5', custom_objects={'data_augmentation': data_augmentation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEt2732uJNJp"
   },
   "source": [
    "### Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 422,
     "status": "ok",
     "timestamp": 1671101298915,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "HITTO_HiJQgw"
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    x = input_layer\n",
    "\n",
    "    # ---------------------------\n",
    "    \n",
    "    # best number of CNN1D layers\n",
    "    num_cnn_layers = hp.Int('n_1dcnn_layers',0,8)\n",
    "    filters = [2**i for i in range(6,6+num_cnn_layers)]\n",
    "    for f in filters:\n",
    "        x = Conv1D(f,3,padding='same',activation='relu')(x)\n",
    "    \n",
    "    # ---------------------------\n",
    "\n",
    "    # best number of LSTM layers\n",
    "    for i in range(hp.Int('n_lstm_layers',1,4)):\n",
    "        x = Bidirectional(LSTM(\n",
    "            hp.Int(f'LSTM_units_{i}', min_value=64, max_value=256, step=64), return_sequences=True))(x)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x = Dropout(rate=hp.Choice(f'dropout_post_GAP_rate', values=[0.0,0.5]))(x)\n",
    "\n",
    "    # ---------------------------\n",
    "\n",
    "    # best number of Dense layers\n",
    "    for i in range(hp.Int('n_dense_layers',1,2)):\n",
    "        x = Dense(units=hp.Int(f'dense_units_{i}', min_value=128, max_value=512, step=128))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(rate=hp.Choice(f'dropout_post_dense_{i}_rate', values=[0.0,0.5]))(x)\n",
    "\n",
    "    # ---------------------------\n",
    "\n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # best lr\n",
    "    # hp_learning_rate = hp.Choice('learning_rate',values=[1e-2,1e-3,1e-4])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1039,
     "status": "ok",
     "timestamp": 1671103130506,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "nB_pYsOseIE8"
   },
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel=model_builder,\n",
    "    objective='val_accuracy',\n",
    "    directory=LOG_DIR,\n",
    "    max_trials=30, # 10 default\n",
    "    project_name='BayOpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGJmZUCdJfbC",
    "outputId": "e17fa987-b1aa-45c9-d3e2-773e4a4bcfa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.search(X_train,\n",
    "             y_train,\n",
    "             epochs=30,\n",
    "             validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD2uPU0hJk13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1671102120641,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "L6tgUcR8Jl9R",
    "outputId": "1eb54df1-e9e5-4917-b37a-31ad47b58f8c"
   },
   "outputs": [],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "best_hp.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the model with the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1671102163754,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "e5fOq3teJprU",
    "outputId": "626d0daf-c4bb-4c18-fcc3-0e74cdd54821"
   },
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89032,
     "status": "ok",
     "timestamp": 1671102284760,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "2Vqm34Clc8MU",
    "outputId": "93cf95b0-c39b-4521-efbf-51fd4667bc67",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, save=True, filename='history_tuner', show_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "executionInfo": {
     "elapsed": 2033,
     "status": "ok",
     "timestamp": 1671102294232,
     "user": {
      "displayName": "Teo Bucci",
      "userId": "15270228491323971360"
     },
     "user_tz": -60
    },
    "id": "BDTdVxPpdTju",
    "outputId": "118506d4-1866-41ee-db4e-e014948b5c3d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODELS_DIR / 'tuner-0.7452')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR / 'tuner-0.7452')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcHzgkB0Xy45"
   },
   "source": [
    "### Inception Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yb-CDekcX4HM"
   },
   "outputs": [],
   "source": [
    "def inception_module(input_layer, bottleneck_size, filters, kernel_size, activation,stride=1):\n",
    "    \n",
    "    input_inception = Conv1D(filters=bottleneck_size, kernel_size=1,\n",
    "                             padding='same', activation=activation, use_bias=False)(input_layer)\n",
    "    \n",
    "    kernel_size_s = [kernel_size // (2 ** i) for i in range(3)]\n",
    "    conv_list = []\n",
    "    for i in range(len(kernel_size_s)):\n",
    "        conv_list.append(Conv1D(filters=filters, kernel_size=kernel_size_s[i],\n",
    "                                strides=stride, padding='same', activation=activation, use_bias=False)(input_inception))\n",
    "    \n",
    "    max_pool = MaxPooling1D(pool_size=3, strides=stride, padding='same')(input_layer)\n",
    "    \n",
    "    conv = Conv1D(filters=filters, kernel_size=1,\n",
    "                    padding='same', activation=activation, use_bias=False)(max_pool)\n",
    "    \n",
    "    conv_list.append(conv)\n",
    "\n",
    "    x = Concatenate(axis=2)(conv_list)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def shortcut_layer(input_layer, output_layer):\n",
    "    y = Conv1D(filters=int(output_layer.shape[-1]), kernel_size=1,\n",
    "               padding='same', use_bias=False)(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    x = Add()([y,output_layer])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUtObKwzYCI6"
   },
   "outputs": [],
   "source": [
    "def build_InceptionTime_classifier(depth, bottleneck_size, filters, kernel_size, activation, aug=False):\n",
    "\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    x = input_layer\n",
    "    \n",
    "    if aug:\n",
    "        x = data_augmentation()(x)\n",
    "    \n",
    "    input_res = x\n",
    "\n",
    "    # inception block\n",
    "    for d in range(depth):\n",
    "        x = inception_module(x, bottleneck_size, filters, kernel_size, activation)\n",
    "        if d%3 == 2:\n",
    "            x = shortcut_layer(input_res,x)\n",
    "            input_res = x\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Classifier\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    \n",
    "    output_layer = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy', run_eagerly=aug)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2559,
     "status": "ok",
     "timestamp": 1670885424188,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "4jfQLRn0YN1s",
    "outputId": "b6fb52fc-4205-4f1b-902d-38d3f217d32a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_InceptionTime_classifier(depth=6, bottleneck_size=32, filters=128, kernel_size=40, activation='tanh', aug=AUGMENTATION)\n",
    "model._name = 'inception_time'\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mAmaKtjPxX0A"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=REPORT_DIR / 'model_inception_time.pdf', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT5kqrxTYN1u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, model = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1670877864037,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "oDVCYWrWYN1v",
    "outputId": "10482991-d0b1-4312-e61f-09e58953ce4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history, save=True, filename='history_inception', show_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7123,
     "status": "ok",
     "timestamp": 1670877928928,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "O-5Tu9fE_K_t",
    "outputId": "012ccea3-598e-4be4-d7cf-89a3e37d5e87"
   },
   "outputs": [],
   "source": [
    "model.save(MODELS_DIR / 'inception-0.7616.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR / 'inception-0.7616.h5', custom_objects={'data_augmentation': data_augmentation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_C0o3bws3vqo",
    "tags": []
   },
   "source": [
    "### Inception Time Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRAZY_ENSEMBLE_DIR = MODELS_DIR / 'inception_weighted'\n",
    "CRAZY_ENSEMBLE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2914757,
     "status": "ok",
     "timestamp": 1670880916829,
     "user": {
      "displayName": "paolo botta",
      "userId": "08338707820961020081"
     },
     "user_tz": -60
    },
    "id": "A5kyHe0UUCBF",
    "outputId": "a6603083-4471-44e8-e17a-4406a3d4f998",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare the 12 models\n",
    "\n",
    "for classToImprove in range(12):\n",
    "    \n",
    "    # build model\n",
    "    model = build_InceptionTime_classifier(depth=6, bottleneck_size=32, filters=128, kernel_size=40, activation='tanh', aug=AUGMENTATION)\n",
    "\n",
    "    # assign weight\n",
    "    class_weights = dict(zip(range(0,12),np.ones(12)))\n",
    "    class_weights[classToImprove] = 10\n",
    "\n",
    "    # train model\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val,y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True),\n",
    "            keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=10, factor=0.5, min_lr=1e-5)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    filename = f'inception_weighted_class_{classToImprove}.h5'\n",
    "    model.save(CRAZY_ENSEMBLE_DIR / filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_flip = dict((v,k) for k,v in label_mapping.items())\n",
    "label_mapping_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show accuracy of each model\n",
    "for i in range(12):\n",
    "    filename = f'inception_weighted_class_{i}.h5'\n",
    "    model = keras.models.load_model(CRAZY_ENSEMBLE_DIR / filename, custom_objects={'data_augmentation': data_augmentation})\n",
    "    predictions = model.predict(X_val, verbose=0)\n",
    "    acc = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n",
    "    print(f'Model tuned on class {label_mapping_flip[i]:<14} | Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9n56Vue4-6fx"
   },
   "outputs": [],
   "source": [
    "# load models\n",
    "model_inception_base = keras.models.load_model(MODELS_DIR / 'inception-0.7616.h5', custom_objects={'data_augmentation': data_augmentation})\n",
    "models = [model_inception_base]\n",
    "for i in range(12):\n",
    "    filename = f'inception_weighted_class_{i}.h5'\n",
    "    model = keras.models.load_model(CRAZY_ENSEMBLE_DIR / filename, custom_objects={'data_augmentation': data_augmentation})\n",
    "    model._name = f'model_class_{i}'\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwYNLfKI-vrP"
   },
   "outputs": [],
   "source": [
    "# build ensemble\n",
    "inputs = Input(shape=INPUT_SHAPE)\n",
    "outputs = [model(inputs) for model in models]\n",
    "outputs_ensemble = Average()(outputs)\n",
    "model_ensemble = Model(inputs=inputs, outputs=outputs_ensemble, name='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model_ensemble, to_file=REPORT_DIR / 'model_inception_ensemble.pdf', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model_ensemble, X_val, y_val, save=True, filename='confusion_crazy_ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZWAmbTny_vfo",
    "outputId": "84ed7ddc-76be-423d-afca-20142ed22fc9"
   },
   "outputs": [],
   "source": [
    "model_ensemble.save(MODELS_DIR / 'inception_crazy_ensemble-0.7699.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = keras.models.load_model(MODELS_DIR / 'inception_crazy_ensemble-0.7699.h5', custom_objects={'data_augmentation': data_augmentation})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1t3CIk-WfpT7_YtHK63LwhnsXzY3HSYVo",
     "timestamp": 1671008095990
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
